{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first DCGAN ðŸŒ±\n",
    "- DCGAN [paper](https://arxiv.org/abs/1511.06434)\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Gan Archtecture Scheme</b>\n",
    "</font>\n",
    "</summary>\n",
    "<div>\n",
    "<img src = \"layers.png\" width=800>\n",
    "</div>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels, hidden_units) -> None:\n",
    "        \"\"\"Discriminator model for DCGAN architecture based\n",
    "         on Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks paper.\n",
    "         Paper: https://arxiv.org/abs/1511.06434\n",
    "\n",
    "        Args:\n",
    "            img_channels (int): Number of channels of the image (for example for RGB its 3).\n",
    "            hidden_units (int): Number of neurons in hidden layer.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # First discriminator block (bo batch norm)\n",
    "            nn.Conv2d(img_channels, hidden_units, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Rest of the blocks...\n",
    "            self._block(in_channels=hidden_units, out_channels=hidden_units * 2),\n",
    "            self._block(in_channels=hidden_units * 2, out_channels=hidden_units * 4),\n",
    "            self._block(in_channels=hidden_units * 4, out_channels=hidden_units * 8),\n",
    "            nn.Conv2d(in_channels=hidden_units * 8, out_channels=1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid(), # Output range [0, 1]\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel__size=4, stride=2, padding=1) -> torch.Tensor:\n",
    "        \"\"\"Creates a single discriminator block consisting of a convolution layer, batch normalization and Leaky ReLU.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "                out_channels (int): Number of output channels.\n",
    "                kernel_size (int, optional): Size of convolution filter. Defaults to 4.\n",
    "                stride (int, optional): Stride size. Defaults to 2.\n",
    "                padding (int, optional): Amount of pixels added around the image. Defaults to 1.\n",
    "        Returns:\n",
    "            torch.Tensor: Returns a tensor with performed convolutions.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel__size, stride, padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim: int, img_channels: int, hidden_units: int) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            z_dim (int): Dimension of the noise vector used for image generation.\n",
    "            img_channels (int): Number of channels in the generated image.\n",
    "            hidden_units (int): Number of neurons in the hidden layer.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # First generator block\n",
    "            self._generator_block(\n",
    "                in_channels=z_dim,\n",
    "                out_channels=hidden_units * 16,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            # Rest of the generator blocks...\n",
    "            self._generator_block(\n",
    "                in_channels=hidden_units * 16, out_channels=hidden_units * 8\n",
    "            ),\n",
    "            self._generator_block(\n",
    "                in_channels=hidden_units * 8, out_channels=hidden_units * 4\n",
    "            ),\n",
    "            self._generator_block(\n",
    "                in_channels=hidden_units * 4, out_channels=hidden_units * 2\n",
    "            ),\n",
    "            # Final block\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=hidden_units * 2,\n",
    "                out_channels=img_channels,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.Tanh(),  # Output range: [-1, 1]\n",
    "        )\n",
    "\n",
    "    def _generator_block(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 4,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Creates a single generator block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int, optional): Size of convolution filter. Defaults to 4.\n",
    "            stride (int, optional): Stride size. Defaults to 2.\n",
    "            padding (int, optional): Amount of pixels added around the image. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Returns a tensor with performed convolutions.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.gen(x)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model: nn.Module) -> None:\n",
    "    \"\"\"Initializes weights using a normal distribution with mean 0 and std 0.02.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The generator or discriminator model.\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        # if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def test_weights_initialization() -> None:\n",
    "    \"\"\"Tests the initialize_weights() function\"\"\"\n",
    "    N, C, H, W = 8, 3, 64, 64\n",
    "    z_dim = 100\n",
    "\n",
    "    x = torch.randn(\n",
    "        (N, C, H, W)\n",
    "    )  # Simulate a random batch of images of shape N x C x H x W\n",
    "\n",
    "    ### Test Discriminator\n",
    "    disc = Discriminator(img_channels=C, hidden_units=8)\n",
    "    initialize_weights(model=disc)\n",
    "\n",
    "    # There should be outputet one prediction per image\n",
    "    assert disc(x).shape == (N, 1, 1, 1), \"Discriminators weights are not initialized correctly.\"\n",
    "\n",
    "    ### Test Generator\n",
    "    gen = Generator(z_dim=z_dim, img_channels=C, hidden_units=8)\n",
    "    initialize_weights(model=gen)\n",
    "    \n",
    "    noise = torch.randn((N, z_dim, 1, 1))\n",
    "    fake_image = gen(noise)\n",
    "    \n",
    "    assert fake_image.shape == (\n",
    "        N,\n",
    "        C,\n",
    "        H,\n",
    "        W,\n",
    "    ), f\"Generators weights are not initialized correctly. Instead of ({N}, {C}, {H}, {W}) they are {fake_image.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
